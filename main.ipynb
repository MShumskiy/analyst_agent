{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\projects\\ai_based\\agent\\a_3_1_git\\analyst_agent\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "g:\\projects\\ai_based\\agent\\a_3_1_git\\analyst_agent\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 1950.39it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 12.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 10/10 [00:00<00:00, 3316.97it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 10/10 [00:57<00:00,  5.74s/it]\n"
     ]
    }
   ],
   "source": [
    "# frontend.py\n",
    "\n",
    "import gradio as gr\n",
    "from agent import Agent  # Ensure agent.py is in the same directory or adjust the import path\n",
    "import requests\n",
    "import datetime\n",
    "from tools.Tools import *\n",
    "from tools.Prompts import *\n",
    "\n",
    "\n",
    "# Initialize your Agent\n",
    "tools = {\n",
    "        'lin_reg':lin_reg\n",
    "}\n",
    "\n",
    "model_name = 'microsoft/Phi-3-mini-4k-instruct'\n",
    "\n",
    "agent = Agent(system_prompt, model_name, tools)\n",
    "\n",
    "def chat_interface(user_input, history):\n",
    "    \"\"\"\n",
    "    Gradio interface function to handle user input and agent response.\n",
    "\n",
    "    Parameters:\n",
    "    user_input (str): The user's input prompt.\n",
    "    history (list): The conversation history.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Updated history and the latest response along with image if any.\n",
    "    \"\"\"\n",
    "    response, image_path = agent.process_prompt(user_input)\n",
    "    history = history + [(user_input, response)]\n",
    "    if image_path and os.path.exists(image_path):\n",
    "        return history, history, image_path\n",
    "    else:\n",
    "        return history, history, None\n",
    "\n",
    "# Define Gradio Blocks\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"<h1 align='center'>AI Agent Chat Interface</h1>\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            chatbot = gr.Chatbot()\n",
    "            user_input = gr.Textbox(show_label=False, placeholder=\"Enter your message here...\")\n",
    "            submit = gr.Button(\"Send\")\n",
    "        with gr.Column():\n",
    "            image_output = gr.Image(label=\"Generated Plot\")\n",
    "\n",
    "    # Initialize conversation history\n",
    "    state = gr.State([])\n",
    "\n",
    "    submit.click(\n",
    "        fn=chat_interface,\n",
    "        inputs=[user_input, state],\n",
    "        outputs=[state, chatbot, image_output],\n",
    "    )\n",
    "    user_input.submit(\n",
    "        fn=chat_interface,\n",
    "        inputs=[user_input, state],\n",
    "        outputs=[state, chatbot, image_output],\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
