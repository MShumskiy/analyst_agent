{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = 'H:/huggingface'\n",
    "os.environ['TRANSFORMERS_CACHE'] = 'H:/huggingface/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\projects\\ai_based\\agent\\a_3_1_git\\analyst_agent\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f4b73cc8534c55ac50346edeb5aa97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91df439fe49349148ee05518a3291dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: unterminated string literal (detected at line 1) (<unknown>, line 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b626f7358846fe8bf6b452f4d216cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8366a1e216ab4600aa9f601d8d5732ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenization_qwen.py:   0%|          | 0.00/21.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f811ff4f711040808cba3155f5953d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "qwen.tiktoken:   0%|          | 0.00/2.56M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751e063d4bca466f87c4aa8a4ae75218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbf207396c84e33a7f3ccb719df9ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_qwen.py:   0%|          | 0.00/2.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b82cc85d7147f5aaa4032529189d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_qwen.py:   0%|          | 0.00/44.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7372190e673418b8385fba3b9853bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "qwen_generation_utils.py:   0%|          | 0.00/14.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5eb9d4b7b4841368ba339e8c4eaf68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "visual.py:   0%|          | 0.00/14.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebd091c9482408a8d1e50e2ff5cda4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/79.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c81be09b3274a158a05570980831053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ad18f86ae748f99fb9e3f1e6f84e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00010.bin:   0%|          | 0.00/1.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276352fb62f8463680e0cee1c0a3e3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00010.bin:   0%|          | 0.00/1.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af2a7c34adf452da95e78a61bf3dd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00003-of-00010.bin:   0%|          | 0.00/1.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# frontend.py\n",
    "\n",
    "import gradio as gr\n",
    "from agent import Agent  # Ensure agent.py is in the same directory or adjust the import path\n",
    "import requests\n",
    "import datetime\n",
    "from tools.Tools import *\n",
    "from tools.Prompts import *\n",
    "\n",
    "\n",
    "# Initialize your Agent\n",
    "tools = {\n",
    "        'lin_reg':lin_reg\n",
    "}\n",
    "\n",
    "model_name = 'microsoft/Phi-3-mini-4k-instruct'\n",
    "\n",
    "agent = Agent(system_prompt, model_name, tools)\n",
    "\n",
    "def chat_interface(user_input, history):\n",
    "    \"\"\"\n",
    "    Gradio interface function to handle user input and agent response.\n",
    "\n",
    "    Parameters:\n",
    "    user_input (str): The user's input prompt.\n",
    "    history (list): The conversation history.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Updated history and the latest response along with image if any.\n",
    "    \"\"\"\n",
    "    response, image_path = agent.process_prompt(user_input)\n",
    "    history = history + [(user_input, response)]\n",
    "    if image_path and os.path.exists(image_path):\n",
    "        return history, history, image_path,''\n",
    "    else:\n",
    "        return history, history, None,''\n",
    "\n",
    "# Define Gradio Blocks\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"<h1 align='center'>AI Agent Chat Interface</h1>\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            chatbot = gr.Chatbot()\n",
    "            user_input = gr.Textbox(show_label=False, placeholder=\"Enter your message here...\")\n",
    "            submit = gr.Button(\"Send\")\n",
    "        with gr.Column():\n",
    "            image_output = gr.Image(label=\"Generated Plot\")\n",
    "\n",
    "    # Initialize conversation history\n",
    "    state = gr.State([])\n",
    "\n",
    "    submit.click(\n",
    "        fn=chat_interface,\n",
    "        inputs=[user_input, state],\n",
    "        outputs=[state, chatbot, image_output,user_input],\n",
    "    )\n",
    "    user_input.submit(\n",
    "        fn=chat_interface,\n",
    "        inputs=[user_input, state],\n",
    "        outputs=[state, chatbot, image_output,user_input],\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
